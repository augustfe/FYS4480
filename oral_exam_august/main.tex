\documentclass[UKenglish,aspectratio=169]{beamer}
\usepackage[utf8]{inputenc}
\usepackage{babel, textcomp}
\usepackage{arevtext}
\usepackage{microtype}
\usepackage{appendixnumberbeamer}

\usepackage{tikz}

\usepackage{amsmath, amssymb}
% \usepackage{caption}

\usepackage{hyperref}
\usepackage{xcolor}
% \hypersetup{ % this is just my personal choice, feel free to change things
%     colorlinks,
%     linkcolor={red!50!black},
%     citecolor={blue!50!black},
%     urlcolor={blue!80!black},
% }

\usetheme[
    uiostandard,
    font=none,
    sectionsep=uiogreen1,
]{UiO}
\usefonttheme{professionalfonts}
\usefonttheme[onlymath]{serif}
\urlstyle{sf}

\newcommand*\diff{\mathop{}\!\mathrm{d}}

\title{FYS4480 Oral Exam}
\subtitle{Quantum mechanics for many-particle systems}
\author{August Femtehjell}
\uioemail{august.femtehjell@fys.uio.no}

\begin{document}
\uiofrontpage[
    % info={A minimal user guide},
    % image={uio-beamer-segl-pos},
    date={16th December, 2024},
]

\section{Introduction}
\begin{frame}{Notation}
    Here, we follow the notation of having states $ijk\ldots$ refer to occupied states, and $abc\ldots$ refer to unoccupied states, typically below and above the Fermi level, respectively.
    From a reference state $\lvert \Phi_0 \rangle$ with $N$ particles, we write a 1-particle-1-hole (1p1h) excitation as
    \begin{equation}
        \lvert \Phi_{i}^{a} \rangle
        = a_{a}^\dagger a_{i} \lvert \Phi_0 \rangle,
    \end{equation}
    and similarly for 2p2h, 3p3h, etc.
\end{frame}

\begin{frame}{Motivation}
    We are, in essence, interested in finding the ground state energy of a many-body system, that is, solving the eigenvalue problem
    \begin{equation}
        \hat{H} \lvert \Psi_0 \rangle = E_0 \lvert \Psi_0 \rangle,
    \end{equation}
    where $\hat{H}$ is the Hamiltonian operator and $\lvert \Psi_0 \rangle$ is the ground state wave function, such that the ground state energy $E_0$ is minimized.

    \bigskip

    The complexity arises from the fact that the exact solution cannot typically be found for systems with more than a few particles, and we must resort to approximations.
\end{frame}

\section{Full configuration interaction}

\begin{frame}{Full configuration interaction theory}
    In full configuration interaction (FCI) theory, we seek to write the wave function as a linear combination of all possible Slater determinants, that is, all possible configurations of the system, truncated at some level.

    \bigskip

    That is, we with to write the wave function as
    \begin{equation}
        \lvert \Psi_0 \rangle = C_0 \lvert \Phi_0 \rangle + \sum_{ia} C_i^a \lvert \Phi_i^a \rangle + \sum_{ijab} C_{ij}^{ab} \lvert \Phi_{ij}^{ab} \rangle + \ldots,
    \end{equation}
    where the coefficients $C$ are determined by solving the eigenvalue problem.
\end{frame}

\begin{frame}{Slater determinants for pairing model}
    \begin{figure}[htbp]
        \centering
        \input{FCI_states.tex}
        \caption{
            Schematic representation of the six possible Slater determinants for a system with four particles, under the constraint of no broken pairs, total spin $S = 0$, considering only the four lowest levels $p = 1, 2, 3, 4$.\label{fig:SDs}
        }
    \end{figure}
\end{frame}

\begin{frame}{Solving the problem}
    In solving the system, one first has to set up the Hamiltonian matrix, with elements
    \begin{equation}
        H_{i, j} = \langle \Phi_i \lvert \hat{H} \rvert \Phi_j \rangle,
    \end{equation}
    and then diagonalize the matrix to find the eigenvalues and eigenvectors.
    The ground state energy can then be found as the lowest eigenvalue, with the corresponding eigenvector giving the coefficients $C$.

    \bigskip

    FCI is exact, but computationally expensive, as the number of configurations grows factorially with the number of energy levels included.
    Approximative methods are therefore required.
\end{frame}

% \begin{frame}
%     The method consists of the following steps:
%     \begin{enumerate}
%         \item Choose a basis set $\lvert \psi_i \rangle$.
%         \item Construct the Hamiltonian matrix.
%         \item Diagonalize the Hamiltonian matrix.
%         \item Calculate the expectation value of the energy.
%     \end{enumerate}

%     \bigskip

%     The method is exact as it includes all possible configurations of the system, but it is computationally expensive.

%     \begin{equation*}
%         -\frac{1}{2} \sum_{\substack{ab \\ ijkl}} \frac{
%             \langle li \vert V \vert lk \rangle
%             \langle kj \vert V \vert ab \rangle
%             \langle ab \vert V \vert ij \rangle
%         }{
%             (
%                 \varepsilon_i + \varepsilon_j - \varepsilon_a - \varepsilon_b
%             )(
%                 \varepsilon_k + \varepsilon_j - \varepsilon_a - \varepsilon_b
%             )
%         }
%     \end{equation*}
% \end{frame}

\section{Hartree-Fock}

\begin{frame}{Hartree-Fock theory}
    In Hatree-Fock (HF) theory, assume that the system can be approximated by a single Slater determinant, that is, a single configuration.
\end{frame}

\section{Many-body pertubation}
\subsection{Brillouin-Wigner pertubation}
\subsection{Rayleigh-Schr√∂dinger pertubation}

\section{Coupled-Clusted theory}

\appendix
\section{Derivation of the HF equations}

\begin{frame}{Derivation of the HF equations}
    In the original basis $\alpha$ we have the energy functional
    \begin{equation}
        E[\Phi]
        = \left\langle \Phi \vert \hat{H} \vert \Phi \right\rangle
        = \sum_{\alpha} \langle \alpha \vert \hat{h}_0 \vert \alpha \rangle
        + \frac{1}{2} \sum_{\alpha\beta} \langle \alpha\beta \vert V \vert \alpha \beta \rangle_{AS}.
    \end{equation}
    The HF equations are found by introducing the new basis $p$ defined by the unitary transformation
    \begin{equation}
        \psi_p = \sum_{\alpha} C_{p\alpha} \phi_\alpha,
    \end{equation}
    and minimizing the energy functional
    \begin{equation}\label{eq:PhiHF}
        E[\Phi^\mathrm{HF}]
        = \left\langle \Phi^\mathrm{HF} \vert \hat{H} \vert \Phi^\mathrm{HF} \right\rangle
        = \sum_{i} \langle i \vert \hat{h}_0 \vert i \rangle + \frac{1}{2} \sum_{ij} \langle ij \vert V \vert ij \rangle_{AS}
    \end{equation}
    with respect to the coefficients $C_{p\alpha}$. Eq.~\eqref{eq:PhiHF}
\end{frame}

\begin{frame}{Introducing Lagrange multipliers}
    Defining the functional in Eq.~\eqref{eq:PhiHF} as a functional of the coefficients $C_{p\alpha}$, we have
    \begin{equation}%\label{eq:E0}
        E_0[C]
        = \sum_{i} \sum_{\alpha\beta} {
            C_{i \alpha}^*
            C_{i \beta}
            \langle \alpha \vert \hat{h}_0 \vert \beta \rangle
        }
        + \frac{1}{2} \sum_{ij} \sum_{\alpha\beta\gamma\delta} {
            C_{i \alpha}^*
            C_{j \beta}^*
            C_{i \gamma}
            C_{j \delta}
            \langle \alpha\beta \vert V \vert \gamma\delta \rangle_{AS}
        }.
    \end{equation}
    As we have orthonormal basis functions, we have
    \begin{equation}
        \langle i \vert j \rangle
        = \delta_{ij} = \sum_{\alpha\beta} C_{i\alpha}^* C_{i\beta} \langle \alpha \vert \beta \rangle = \sum_{\alpha} C_{i\alpha}^* C_{i\alpha},
    \end{equation}
    so we introduce the functional
    \begin{equation}
        F[C] = E_0[C] - \sum_{i} \lambda_i \sum_{\alpha} C_{i\alpha}^* C_{i\alpha},
    \end{equation}
    where $\lambda_i$ are the Lagrange multipliers enforcing orthonormality.
\end{frame}

\begin{frame}{Minimizing $F$}
    Minimizing $F$ with respect to $C^*_{i\alpha}$, we wish to solve
    \begin{equation}
        \frac{\diff F}{\diff C^*_{i\alpha}}[C] = \frac{\diff}{\diff C_{i \alpha}^*} \left[ E_0[C] - \sum_j \lambda_j \sum_{\alpha} C_{j \alpha}^* C_{j \alpha} \right] = 0.
    \end{equation}

    Term by term we have
    \begin{align}
        \frac{\diff}{\diff C_{i \alpha}^*} \sum_{i} \sum_{\alpha\beta} C_{i \alpha}^* C_{i \beta}
        \langle \alpha \vert \hat{h}_0 \vert \beta \rangle
        &= \sum_{\beta} C_{i \beta}
        \langle \alpha \vert \hat{h}_0 \vert \beta \rangle \\
        \frac{\diff}{\diff C_{i \alpha}^*}
        \frac{1}{2} \sum_{ij} \sum_{\alpha\beta\gamma\delta} C_{i \alpha}^* C_{j \beta}^* C_{i \gamma} C_{j \delta}
        \langle \alpha\beta \vert V \vert \gamma\delta \rangle_{AS}
        &= \sum_j \sum_{\beta\gamma\delta} C_{j \beta}^* C_{i \gamma} C_{j \delta} \langle \alpha\beta \vert V \vert \gamma\delta \rangle_{AS},
    \end{align}
\end{frame}

\begin{frame}{Minimizing $F$, cont.}
    and finally
    \begin{equation}
        \frac{\diff}{\diff C_{i \alpha}^*} \sum_{i} \lambda_i \sum_{\alpha} C_{i \alpha}^* C_{i \alpha} = \lambda_i C_{i \alpha}.
    \end{equation}

    \bigskip

    Combining these terms, we have
    \begin{equation}
        \sum_{\beta} C_{i \beta}
        \langle \alpha \vert \hat{h}_0 \vert \beta \rangle
        + \sum_j \sum_{\beta\gamma\delta} C_{j \beta}^* C_{i \gamma} C_{j \delta} \langle \alpha\beta \vert V \vert \gamma\delta \rangle_{AS}
        - \lambda_i C_{i \alpha} = 0.
    \end{equation}

    Recognizing $\lambda_i$ as the eigenvalues $\varepsilon_i^\mathrm{HF}$, we can write this as
    \begin{equation}
        \sum_{\gamma} \left[
            \langle \alpha \vert \hat{h}_0 \vert \gamma \rangle
            + \sum_j \sum_{\beta\delta} C_{j \beta}^*  C_{j \delta}
            \langle \alpha\beta \vert V \vert \gamma\delta \rangle_{AS}
        \right] C_{p \gamma}
        = \varepsilon_p^\mathrm{HF} C_{p \alpha}.
    \end{equation}
\end{frame}

\begin{frame}{Hartree-Fock equations found}
    This finally results in the HF equations
    \begin{equation}
        \sum_{\gamma} h_{\alpha\gamma}^\mathrm{HF} C_{p \gamma} = \varepsilon_p^\mathrm{HF} C_{p \alpha}.
    \end{equation}
\end{frame}

\end{document}
